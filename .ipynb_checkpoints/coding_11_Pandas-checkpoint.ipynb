{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this unit we will learn the basics of analyzing structured data. In the process we will cover:\n",
    "\n",
    "* What is structured data\n",
    "* How to use Pandas to read and write structured data\n",
    "* Basic indexing operations of Pandas\n",
    "* Basic operations (math and plotting) with Pandas\n",
    "* Handling dates and times\n",
    "* The 'split-apply-combine' framework for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:22.582506Z",
     "start_time": "2022-07-08T21:44:21.421855Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:54.391576Z",
     "start_time": "2022-07-08T21:45:54.359594Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:22.841866Z",
     "start_time": "2022-07-08T21:44:22.827824Z"
    }
   },
   "outputs": [],
   "source": [
    "#We turn off the latex usage in matplotlib because LaTeX doesn't know\n",
    "#how to handle a '_' character without it being escaped with a backslash\n",
    "#Since we use '_' in column names typically this can be a bit of a problem\n",
    "#If we don't turn this off\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Pandas\n",
    "\n",
    "Pandas is a contraction for \"panel data\", such as what you create when using a spreadsheet. Pandas can do a lot, so I find it easier to think of it as this for data:\n",
    "\n",
    "![party](http://cdn.protoolreviews.com/wp-content/uploads/ptr/4433.jpg)\n",
    "\n",
    "But first let's confront the ugly reality.\n",
    "\n",
    "## Pandas is not very Pythonic\n",
    "\n",
    "Actually **using** Pandas and not just using it to read files can be conceptually difficult and is a bit of a mental switch compared to most of what we have learned so far. If you want to iterate over things, you can't use a `for` loop easily. Instead you'll need to use specific Pandas methods to do whatever functions you want. These little differences add up and can wear on you, which might make you want to stop using Pandas. That's a fine way to feel (you don't really *have* to use it), but there are some big benefits to using it, that for a lot of people, are worth the costs.\n",
    "\n",
    "## Benefits of Pandas\n",
    "\n",
    "1. Pandas handles a lot of file I/O drudgery for you. I'll show you this in a bit, but reading CSV files and accessing data in them is super simple\n",
    "2. Pandas has a lot of *magic* built into, automaticallly taking care of many type conversions after reading a file\n",
    "3. Using Pandas **is** like working with [SQL](https://en.wikipedia.org/wiki/SQL) (don't know what SQL is? Don't worry, it's a bit advanced for this course but is surely something you'll encounter if you continue to program so it's worth reading up on). So learning Pandas means that you'll have a good idea of the underpinnings how SQL databases work which might help you later in your programming education (although the syntax is different).\n",
    "\n",
    "If you like using or want to continue using Pandas here is some recommended additional reading\n",
    "\n",
    "The Pandas tutorial pages http://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "\n",
    "10 minutes to Pandas http://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures in Pandas\n",
    "\n",
    "First, let's show some of this `automagic`. In the `Data` folder there is a folder named `College-Majors` that contains a number of files with information on career outcomes for graduates from a large collection of college majors.\n",
    "\n",
    "Let's load one of those files right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.653041Z",
     "start_time": "2022-07-08T21:44:22.843468Z"
    }
   },
   "outputs": [],
   "source": [
    "cat ../Data/College-Majors/recent_Arts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.696865Z",
     "start_time": "2022-07-08T21:44:23.654858Z"
    }
   },
   "outputs": [],
   "source": [
    "college_folder = Path.cwd().parent / 'Data/College-Majors'\n",
    "file_path = college_folder / 'recent_Arts.csv'\n",
    "pd.read_csv( file_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Pandas reads in a `CSV` it turns it into its own data structure called a `DataFrame`. This `DataFrame` is actually a Python class, you can think of it as just a type of *object*. Our data is inside this *object* and it controls how we can interact with it (so you can see the first difference between this and regular programming).\n",
    "\n",
    "(The nice formatting that makes it look like an Excel spreadsheet is provided by the `Jupyter Notebook`!)\n",
    "\n",
    "Now, let's actually load this `CSV` into a variable so we operate on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.713816Z",
     "start_time": "2022-07-08T21:44:23.698137Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataframes` have `columns` and you can access their names easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.730727Z",
     "start_time": "2022-07-08T21:44:23.714987Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics of a DataFrame\n",
    "\n",
    "Since the object we're working with is a `DataFrame` you'll very frequently see people assign it to a variable named `df`. \n",
    "\n",
    "Specifying a value in a `DataFrame` requires two coordinates: a *column* and an *index*.\n",
    "\n",
    "The **columns** run across the **top**\n",
    "\n",
    "The **indices** run down the **left** (for now, you can think of these as rows)\n",
    "\n",
    "We can get see the possible values for these coordinates by calling them by name from the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.747341Z",
     "start_time": "2022-07-08T21:44:23.731889Z"
    }
   },
   "outputs": [],
   "source": [
    "#The columns are the labels across the top\n",
    "print( df.columns ) \n",
    "print()\n",
    "\n",
    "#The indexes run down the side\n",
    "print( df.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data in Pandas\n",
    "\n",
    "Pandas supports two approaches for accessing data that is stored in a **column**. \n",
    "\n",
    "One approach is the `.attribute` of object (think `string.whitespace`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.764070Z",
     "start_time": "2022-07-08T21:44:23.748693Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df.Major))\n",
    "print()\n",
    "df.Major"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "Notice that the output of using the `.attribute` approach is a different kind of object: a `Series`.\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "The other approach is the `key` in `dictionary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.782528Z",
     "start_time": "2022-07-08T21:44:23.766803Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(df['Major']))\n",
    "print()\n",
    "df['Major']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "You can see that these two approaches are quite interchangeable.  However, the attribute approach is difficult to use if column names include spaces. That is one reason to name columns using `_` instead of ` `.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "In order to access the information from specific 'rows', we must make use of the **indices**. \n",
    "\n",
    "`DataFrame` indices can be treated quite similar to the `indices` in a `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.798032Z",
     "start_time": "2022-07-08T21:44:23.783749Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df['Major'][0] )\n",
    "print()\n",
    "print(df.Major[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing in Pandas\n",
    "\n",
    "We can also access slices of rows in a `dataframe` by using the syntax introduced for `lists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:23.813901Z",
     "start_time": "2022-07-08T21:44:23.799387Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df['Major'][0::2] )\n",
    "print()\n",
    "print(df.Major[6::-2])\n",
    "print()\n",
    "print( df[0::2]['Major'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "However, besides slicing on rows, you may also wish to slice on columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:25.460728Z",
     "start_time": "2022-07-08T21:44:23.815092Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df['Major':'Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah! \n",
    "\n",
    "That does not work!!!\n",
    "\n",
    "We need a method based on labels in order to slice along columns.\n",
    "\n",
    "### `.loc[]`\n",
    "\n",
    "The `.loc[]` approach is intended to work on labels.  \n",
    "\n",
    "**Note that when you are using this approach you have to specify slices for both rows and columns.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:50.499483Z",
     "start_time": "2022-07-08T21:44:50.464923Z"
    }
   },
   "outputs": [],
   "source": [
    "print( type(df.loc[:, 'Major':'Total']) )\n",
    "print()\n",
    "print( df.loc[:, 'Major':'Total'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Notice that the order of the labels matter.  \n",
    "\n",
    "**Indices must came before column names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:51.883933Z",
     "start_time": "2022-07-08T21:44:51.852779Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df.loc['Major'::4, ::2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "We can use `.loc[]` on a `Series` though "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:52.881543Z",
     "start_time": "2022-07-08T21:44:52.852983Z"
    }
   },
   "outputs": [],
   "source": [
    "print( type(df['Major']) )\n",
    "print()\n",
    "print( df['Major'].loc[::2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "but we cannot use `.loc[]` iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:53.972441Z",
     "start_time": "2022-07-08T21:44:53.944649Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df.loc['Major'::4].loc[::2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "### `.iloc[]`\n",
    "\n",
    "The `.iloc[]` approach is integer based and works on the indices.\n",
    "\n",
    "If you notice that 'Major' is the third column, then it follows that\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:55.345504Z",
     "start_time": "2022-07-08T21:44:55.310162Z"
    }
   },
   "outputs": [],
   "source": [
    "print( type(df.iloc[:, 2::4]) )\n",
    "print()\n",
    "print( df.iloc[:, 2::4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "To gain a better understanding of how `.iloc` work, let's sort the `dataframe` so that the `index` labels are **no longer referring to the order of the rows.**\n",
    "\n",
    "We start by sorting the rows of the `dataframe` by the values in the **Total** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:56.582858Z",
     "start_time": "2022-07-08T21:44:56.542420Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total_sorted = df.sort_values('Total', ascending = False)\n",
    "df_total_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice how the numbers in the first (unnamed) column are not in order!**\n",
    "\n",
    "When we use the `.iloc` method on `df_total_sorted` we retrieve the specified rows in this new `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:57.765672Z",
     "start_time": "2022-07-08T21:44:57.730646Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df[3:5]['Major'] )\n",
    "print()\n",
    "\n",
    "print( df_total_sorted[3:5]['Major'] )\n",
    "print()\n",
    "\n",
    "print( df_total_sorted['Major'][3:5] )\n",
    "print()\n",
    "\n",
    "print( df_total_sorted.iloc[3:5, 2])\n",
    "print()\n",
    "\n",
    "print( df_total_sorted.iloc[2, 3:5])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T16:30:30.395041Z",
     "start_time": "2022-07-08T16:30:30.278239Z"
    }
   },
   "source": [
    "Notice how when we use the `key` in `dictionary` approach for column names **the order of the `[]` does not matter.**\n",
    "\n",
    "In contrast, when using the `iloc[]` approach, the order of the indices inside the `[]` matters.  The first one refers to the rows and the second one refers to the columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:44:59.116107Z",
     "start_time": "2022-07-08T21:44:58.951462Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df_total_sorted.iloc[3:5, 'Major'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the column names does not work. We have to use an index.\n",
    "\n",
    "And you also cannot use `iloc[]` with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:05.146132Z",
     "start_time": "2022-07-08T21:45:05.019224Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total_sorted[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "If we call `.loc[]` on `df_total_sorted` we see that it filters by the indices defined in `df` but not in the manner one could expect.  These are now looked not as an order but as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:10.502834Z",
     "start_time": "2022-07-08T21:45:10.470700Z"
    }
   },
   "outputs": [],
   "source": [
    "print( df_total_sorted.loc[3:5, 'Major'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Series`: Pandas' other data type\n",
    "\n",
    "You will recall that earlier on when we retrieved the values from a single column, `pandas` returned a `Series` object.\n",
    "\n",
    "We can create `Series` by pulling a single column or a single row from a `dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:12.995896Z",
     "start_time": "2022-07-08T21:45:12.964898Z"
    }
   },
   "outputs": [],
   "source": [
    "serie_1 = df['Major']\n",
    "print(serie_1)\n",
    "print()\n",
    "\n",
    "serie_2= df_total_sorted.loc[3]\n",
    "print(serie_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "Many of the methods defined on `dataframes` also work on `Series` as long you account for the fact that there is only one column, so you do not need a label for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:14.094859Z",
     "start_time": "2022-07-08T21:45:14.062765Z"
    }
   },
   "outputs": [],
   "source": [
    "print( serie_1[0:6:2] )\n",
    "print()\n",
    "\n",
    "print( serie_2[0:6:2] )\n",
    "print()\n",
    "\n",
    "print( serie_2['Major':'Total'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The benefits from using `pandas`\n",
    "\n",
    "Pandas has a LOT of cool functionality. It can read (and write) `.xls`/`.xlsx` files! \n",
    "\n",
    "**Now you don't need to open a workbook in Excel and save it to a `CSV` when someone sends them to you!**\n",
    "\n",
    "When we read an Excel spreadsheet, all we have to say is what sheet we want to use in the file. You can use either the sheet_name (if it has one) or just give it the index of the sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:15.308311Z",
     "start_time": "2022-07-08T21:45:15.129000Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = college_folder / 'recent_Arts.xlsx'\n",
    "\n",
    "with pd.ExcelFile( file_path ) as reader:\n",
    "    line = ''\n",
    "    for name in reader.sheet_names:\n",
    "        line += f\"\\t{name}\\n\" \n",
    "    print(f\"This excel file has {len(reader.sheet_names)} worksheets.\\n\"\n",
    "          f\"Their names are:\\n{line}\")\n",
    "    \n",
    "    df_arts = reader.parse(sheet_name = 0)\n",
    "\n",
    "df_arts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's not just excel. Pandas can actually read/write a large number of different and really useful file formats that can be essential when working with collaborators who might not be quite so python inclined. This is the full list:\n",
    "\n",
    "        read_csv\n",
    "        read_excel\n",
    "        read_hdf\n",
    "        read_sql\n",
    "        read_json\n",
    "        read_msgpack (experimental)\n",
    "        read_html\n",
    "        read_gbq (experimental)\n",
    "        read_stata\n",
    "        read_clipboard\n",
    "        read_pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Pandas helps you quickly explore and manipulate data as you learn about your dataset basics. One quick benefit is the built-in plotting directly from the dataframe.\n",
    "\n",
    "Let's say that we wanted to make a plot that examined the difference between the majors in terms of the raw employment numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:17.089529Z",
     "start_time": "2022-07-08T21:45:16.949448Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arts['Employed'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it's pretty ugly, but it was also fast and easy!\n",
    "\n",
    "Let's actually think about this for a moment because something magical just happened and we all probably took it for granted.\n",
    "\n",
    "**We just plotted numeric data from the file that I read in with a single command.**\n",
    "\n",
    "**When did I change the type of that data to be an integer so that we could plot it??**\n",
    "\n",
    "You might recall when we read files in the past using `open('super_cool_file.csv')`, **everything was read as a string by default, even numbers!**\n",
    "\n",
    "When we load data with Pandas it automatically converted the 'Employed' column data to integers. In fact, Pandas does this with all of the columns and when it does this it picks the **least** expansive data type that **accommodates all the data in the column**.\n",
    "\n",
    "We can check this, so the `Unemployed` column should be integers also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:18.280917Z",
     "start_time": "2022-07-08T21:45:18.242822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arts['Unemployed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually `int64` which is the data format used by `numpy`.\n",
    "\n",
    "Following on this success, we can expect the `ShareWomen` column to contain `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:19.823022Z",
     "start_time": "2022-07-08T21:45:19.788567Z"
    }
   },
   "outputs": [],
   "source": [
    "df_arts['ShareWomen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to be aware of though, is that if we had a single string in that column of data **none of it would be converted**. \n",
    "\n",
    "All of the read values would be strings because any number can represented as a string, just as text data can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "**Getting back to our goal of plotting the data.**\n",
    "\n",
    "A bar plot is more appropriate for this data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:21.460374Z",
     "start_time": "2022-07-08T21:45:21.350434Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Employed'].plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `;` suppresses `matplotlib` print statements\n",
    "\n",
    "Ah! That's a little bit better!\n",
    "\n",
    "But we should never have a graph without a y-label! To change labels we'll need to operate on the `matplotlib` object. \n",
    "\n",
    "**Applying the method `plot()` to a `DataFrame` returns a `Matplotlib` axis object.**\n",
    "\n",
    "We can then use what we know about `Matplotlib` to customize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:22.739815Z",
     "start_time": "2022-07-08T21:45:22.618417Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'm changing the color of the bars here because the other blue looks awful!\n",
    "#\n",
    "ax = df['Employed'].plot(kind = 'bar', color = 'steelblue')\n",
    "\n",
    "# Now I can set the y-axis label\n",
    "#\n",
    "ax.set_ylabel('Students Employed', fontsize = my_fontsize)\n",
    "\n",
    "# I can also set the xticks to the major names. And \n",
    "#\n",
    "major_labels = df['Major']\n",
    "ax.set_xticklabels(major_labels, rotation = 45, ha = 'right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical operations\n",
    "\n",
    "Pandas has methods implementing numerous mathematical operations built directly into the `dataframe` object using `numpy`. \n",
    "\n",
    "For exampple, if you want to know the average of a column's value or the number of rows with entries (not every position has to have a value!), you can accomplish that in a straightforward manner.\n",
    "\n",
    "Let's start by just counting the number of values in each column (it should be 8 in every column since every spot in our spreadsheet was filled out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:23.914981Z",
     "start_time": "2022-07-08T21:45:23.882396Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['Employed'].count())\n",
    "print()\n",
    "df['Employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:45:24.572236Z",
     "start_time": "2022-07-08T21:45:24.537350Z"
    }
   },
   "outputs": [],
   "source": [
    "help(df.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the documentation that\n",
    "\n",
    ">Count non-NA cells for each column or row.\n",
    ">    \n",
    ">    The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
    "    on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
    "\n",
    "\n",
    "When there is a missing value in the raw data `pandas` replaces that value with a `Not a Number` or `NaN`.\n",
    "\n",
    "We can learn about what this means by creating a new column with no values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:03.060077Z",
     "start_time": "2022-07-08T21:46:03.026776Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Test_column'] = np.nan\n",
    "df.loc[:, 'College_jobs':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we count, it won't be the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:04.269971Z",
     "start_time": "2022-07-08T21:46:04.237368Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Test_column'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count values for the entire `dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:05.296249Z",
     "start_time": "2022-07-08T21:46:05.256056Z"
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "We can also just count a few columns or single column by chaining the `.count()` method after we slice the `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:06.172435Z",
     "start_time": "2022-07-08T21:46:06.137885Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[0:2].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "There are other useful functions built in too. We can quickly take the mean or median of a column also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:07.091412Z",
     "start_time": "2022-07-08T21:46:07.057445Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Employed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:07.586986Z",
     "start_time": "2022-07-08T21:46:07.554116Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Employed.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can even get the mean, medians, and a host of other summary statistics for all columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:08.511431Z",
     "start_time": "2022-07-08T21:46:08.477362Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Employed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:09.045292Z",
     "start_time": "2022-07-08T21:46:09.011384Z"
    }
   },
   "outputs": [],
   "source": [
    "print( type( df.Employed.describe() ) )\n",
    "print()\n",
    "\n",
    "df.Employed.describe()['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe()` method returns a `Series`. \n",
    "\n",
    "Thus, it can be accessed in the usual ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:10.178896Z",
     "start_time": "2022-07-08T21:46:10.141570Z"
    }
   },
   "outputs": [],
   "source": [
    "my_column = 'Men'\n",
    "\n",
    "print(df[my_column].describe()['50%'])\n",
    "print()\n",
    "print(df[my_column].describe()[5])\n",
    "print()\n",
    "print(f\"The median of number of {my_column} is {df[my_column].describe()['50%']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy \"parallelization\" of  code\n",
    "\n",
    "Just as with `numpy`, `pandas` enable us to easily parallelize operations on columns of data. \n",
    "\n",
    "Note that the data types with a single row are unlikely to be identical, so the similar approach for rows would be unlike to work.\n",
    "\n",
    "You can easily implement operations across all values in a column. For example, you can divide the values in a column by the corresponding values in another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:11.380621Z",
     "start_time": "2022-07-08T21:46:11.346783Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Employed']/df['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to save the outcome of this operation, you assign it to another variable or to a new column in the `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:12.437261Z",
     "start_time": "2022-07-08T21:46:12.403522Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Percent_Employed'] = 100 * df.Employed / df.Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.head()` method to print the top few rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:13.419041Z",
     "start_time": "2022-07-08T21:46:13.384287Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'College_jobs':].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "And you can perform more elaborate calculations too... the z-score is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:14.477063Z",
     "start_time": "2022-07-08T21:46:14.443328Z"
    }
   },
   "outputs": [],
   "source": [
    "df['z_score_college_jobs'] = (df.College_jobs - df.College_jobs.mean()) / df.College_jobs.std()\n",
    "df['z_score_college_jobs'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying\n",
    "\n",
    "A great strength of Pandas is the ability to query a `dataframe` and extract only the rows or columns that meet some criteria.\n",
    "\n",
    "For example, imagine you want to focus on those majors with more than 20,000 graduates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:15.572689Z",
     "start_time": "2022-07-08T21:46:15.537552Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following statement parallelizes the comparison of the values in the column *Total* to the value 20,000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:16.548351Z",
     "start_time": "2022-07-08T21:46:16.512211Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Total > 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Boolean `Series` can be used to filter the appropriate rows in the `dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:17.530734Z",
     "start_time": "2022-07-08T21:46:17.490542Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.Total > 20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things get annoying.  `pandas` developers chose, for convenience, I imagine, to settle on a distinct set of symbols for the logical operator:\n",
    "\n",
    "> `|` stands for `or`\n",
    ">\n",
    ">  `&` stands for `and`\n",
    ">\n",
    "> `~` stands for `not`\n",
    "\n",
    "And notice that every individual logical operation must be placed inside parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:18.510939Z",
     "start_time": "2022-07-08T21:46:18.471416Z"
    }
   },
   "outputs": [],
   "source": [
    "df[(df.Total > 20000) | (df.Major_code < 6003)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:19.004659Z",
     "start_time": "2022-07-08T21:46:18.963794Z"
    }
   },
   "outputs": [],
   "source": [
    "df[(df.Total > 20000) & (df.Major_code < 6003)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chain selection operators off of the query also if we want to know a bit more about the resulting column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:20.079368Z",
     "start_time": "2022-07-08T21:46:20.045414Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.Employed > 20000].Unemployment_rate.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Querying is actually a sort of parallelization. It enables us to very compactly tell the computer what operations to implement across all rows or columns. The masks returned by queries could be easily implemented with `for` loops\n",
    "\n",
    "    for total_students in total:\n",
    "        if total_students > 20000:\n",
    "            #Continue with code\n",
    "            \n",
    "However, a large set of indented `if` statements and of `loops` can quickly become unyielding. \n",
    "\n",
    "Conversely, the terseness of `Pandas`' notation can also become an hindrance to readability and a source of logical mistakes. To avoid mistakes, it is good to construct your masks step-by-step and to carefully test how accurate they are at capturing your intent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with dates\n",
    "\n",
    "We talked earlier about how Pandas automagically converts data types when reading a file in. One of the best automagic features is `pandas`' ability to handle dates and times. \n",
    "\n",
    "In order to get a better idea of what Pandas do, it is good to compare with the `datetime`.   `datetime` is complex, sophisticated library that can be a bit unfriendly. For example, the module one typically uses the most has the exact same name as the package itself:\n",
    "\n",
    "Using `import datetime`, one would refer to `datetime.datetime`\n",
    "\n",
    "Using `from datetime import datetime` or `import datetime.datetime as datetime`, one would refer to the same modules simply as `datetime`\n",
    "\n",
    "Earlier, we used `import datetime`.\n",
    "\n",
    "This package has many useful methods and attributes. For example, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:22.535324Z",
     "start_time": "2022-07-08T21:46:22.504321Z"
    }
   },
   "outputs": [],
   "source": [
    "datetime.date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want just the `date` we can use the `date` module in datetime.\n",
    "\n",
    "But typically most people care about what time it is too. To get both the date and the time, we must use the `datetime` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:23.143174Z",
     "start_time": "2022-07-08T21:46:23.109463Z"
    }
   },
   "outputs": [],
   "source": [
    "datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's how dates and times are generated! The benefit is that the time is returned in a `datetime` object so we can access individual parts of the time by name, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:23.546963Z",
     "start_time": "2022-07-08T21:46:23.511529Z"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "print(today.year)\n",
    "print(today.month)\n",
    "print(today.second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "But how do we read in a list of dates? For that we actually have to convert a string using the `datetime.datetime.strptime` function. This function takes two arguments:\n",
    "\n",
    "    1. the string we want to decode\n",
    "    2. a string providing the format of the date we want to decode \n",
    "    \n",
    "The formating string uses a special [symbol set](https://docs.python.org/3/library/datetime.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:23.927516Z",
     "start_time": "2022-07-08T21:46:23.895377Z"
    }
   },
   "outputs": [],
   "source": [
    "datetime.datetime.strptime('2014-01-01', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Sadly, different data sources use different formating for dates and times. Think of the European versus US styles for dates. \n",
    "\n",
    "Fortunately, Pandas can take care of these issues for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:24.411549Z",
     "start_time": "2022-07-08T21:46:24.363613Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = Path.cwd().parent / 'Data'\n",
    "aapl_df = pd.read_csv( data_folder / 'aapl_stock_price.csv' )\n",
    "\n",
    "aapl_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:24.658805Z",
     "start_time": "2022-07-08T21:46:24.625298Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df.Date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It automatically read in the dates! It understands time and can use basic functions with the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:25.440524Z",
     "start_time": "2022-07-08T21:46:25.408896Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:25.927127Z",
     "start_time": "2022-07-08T21:46:25.894834Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df.Date.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and can sort the dataframe based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:26.865676Z",
     "start_time": "2022-07-08T21:46:26.826561Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aapl_df.Date.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "We can also easily select a certain period of time using queries! To specify a date, we don't even have to create a `datetime` object - we can just use a string representation of the time and Pandas will translate it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:27.756142Z",
     "start_time": "2022-07-08T21:46:27.717246Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date > '2015-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:28.250385Z",
     "start_time": "2022-07-08T21:46:28.212867Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[(aapl_df.Date > '2015-08-01') & (aapl_df.Date < '2015-08-18')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these dates can work without specifying the whole date too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:29.150783Z",
     "start_time": "2022-07-08T21:46:29.111110Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date > '2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "However, by default we can't access individual attributes of a date value this way (because the value, despite being worked with as a date isn't a `datetime` object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:30.100047Z",
     "start_time": "2022-07-08T21:46:30.057862Z"
    }
   },
   "outputs": [],
   "source": [
    "print(aapl_df.Date[0])\n",
    "aapl_df.Date[0].month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, `pandas` is actually doing all of this with the date as a string!  \n",
    "\n",
    "If we need real `datetime` objects  though, `pandas` has a function to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:34.833896Z",
     "start_time": "2022-07-08T21:46:34.804364Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df['dt_Date'] = pd.to_datetime(aapl_df.Date)\n",
    "aapl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:35.459731Z",
     "start_time": "2022-07-08T21:46:35.428205Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df.dt_Date[0].day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Another cool feature is Pandas' ability to plot time series and referring directly to dates! You just have to use the column with the `datetime` objects as the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:36.636008Z",
     "start_time": "2022-07-08T21:46:36.604905Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df.set_index('dt_Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:37.356131Z",
     "start_time": "2022-07-08T21:46:37.105939Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = aapl_df.Close.plot(color = 'steelblue', fontsize = my_fontsize)\n",
    "ax.set_ylabel('Closing Price\\n(USD$)', fontsize = 1.3*my_fontsize)\n",
    "ax.set_xlabel('Date', fontsize = 1.3*my_fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful built-in functions\n",
    "\n",
    "`pandas` has a number of built-in methods that are a quite useful with structured analysis. \n",
    "\n",
    "One very useful methods is the `.rolling_mean()`, which calculates a mean given a certain size window (it will come up useful when we have to write a function to do that in the [Sentiment Analysis lesson](Day5_pm2_Sentiment-Analysis.ipynb) )?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:38.550753Z",
     "start_time": "2022-07-08T21:46:38.365874Z"
    }
   },
   "outputs": [],
   "source": [
    "#There are roughly 260 workdays in a year\n",
    "#\n",
    "close_moving_avg = aapl_df['Close'].rolling(260, center = True).mean()\n",
    "print(type(close_moving_avg))\n",
    "print()\n",
    "\n",
    "\n",
    "# Now we just plot it\n",
    "#\n",
    "close_moving_avg.plot( label = 'Moving Average', color='red', lw = 8, \n",
    "                       alpha = 0.5)\n",
    "ax = aapl_df.Close.plot( color = 'steelblue', fontsize = my_fontsize)\n",
    "\n",
    "ax.set_ylabel('Closing Price\\n(USD$)', fontsize = 1.3*my_fontsize)\n",
    "ax.set_xlabel('Date', fontsize = 1.3*my_fontsize);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we were interested in the movement of the stock between each day (i.e. did the stock lose or gain money from one day to another)?  We can do that easily with the `diff()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:39.907578Z",
     "start_time": "2022-07-08T21:46:39.746641Z"
    }
   },
   "outputs": [],
   "source": [
    "close_daily_diff = aapl_df['Close'].diff()\n",
    "\n",
    "ax = close_daily_diff.plot( color = 'steelblue', fontsize = my_fontsize )\n",
    "\n",
    "ax.set_ylabel('Daily Return\\n(USD$)', fontsize = 1.3*my_fontsize)\n",
    "ax.set_xlabel('Date', fontsize = 1.3*my_fontsize);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember at anytime we can restrict the dataset with a query and plot only that portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:41.044056Z",
     "start_time": "2022-07-08T21:46:40.881221Z"
    }
   },
   "outputs": [],
   "source": [
    "close_daily_diff = aapl_df[aapl_df.Date < '2014']['Close'].diff()\n",
    "\n",
    "ax = close_daily_diff.plot( color = 'steelblue', fontsize = my_fontsize )\n",
    "\n",
    "ax.set_ylabel('Daily Return\\n(USD$)', fontsize = 1.3*my_fontsize)\n",
    "ax.set_xlabel('Date', fontsize = 1.3*my_fontsize);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users of `pandas` like to **chain** a lot of operations. \n",
    "\n",
    "**This is not pythonic!**, \n",
    "\n",
    "It makes code harder to read and debug.  When re-factoring make sure to de-convolute your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:42.196808Z",
     "start_time": "2022-07-08T21:46:42.163946Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date < '2014'].Close.diff().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:42.849281Z",
     "start_time": "2022-07-08T21:46:42.815436Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date < '2014'].Close.diff().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:43.319661Z",
     "start_time": "2022-07-08T21:46:43.283647Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date < '2014'].Close.diff().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:44.262959Z",
     "start_time": "2022-07-08T21:46:43.825387Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_df[aapl_df.Date < '2014'].Close.diff().hist(bins=100, color='steelblue', log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting your data out of Pandas\n",
    "\n",
    "`pandas` is really useful for loading data and for the parallelization of some operations. However, some of one prefer to work with dictionaries than `dataframes`.\n",
    "\n",
    "You can cast the data within a row, a column or an entire `dataframe`.  \n",
    "\n",
    "Helpfully, the attribute `.values` returns a `numpy` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:45.323899Z",
     "start_time": "2022-07-08T21:46:45.291387Z"
    }
   },
   "outputs": [],
   "source": [
    "totals = df.Total.values\n",
    "\n",
    "print(type(totals))\n",
    "print()\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also dump the data into a `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:46.358031Z",
     "start_time": "2022-07-08T21:46:46.325340Z"
    }
   },
   "outputs": [],
   "source": [
    "list_totals = df.Total.tolist()\n",
    "\n",
    "print(type(list_totals))\n",
    "print()\n",
    "print(list_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had any of the manipulations we performed here actually been important, we'd of course want to save them. \n",
    "\n",
    "With `pandas`, you can easily export your data in a number of formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:48.042532Z",
     "start_time": "2022-07-08T21:46:47.362969Z"
    }
   },
   "outputs": [],
   "source": [
    "# place cursor after underscore and press Tab\n",
    "#\n",
    "df.to_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T21:46:48.412274Z",
     "start_time": "2022-07-08T21:46:48.354213Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_excel( college_folder / 'recent_Arts_edited.xlsx', sheet_name = 'Arts', \n",
    "             index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises\n",
    "\n",
    "Select three fields for further study (for example, Arts, Business, and Engineering).\n",
    "\n",
    "Read the data from the corresponding `.csv` or `.xlsx` file into a `dictionary` of `dataframes` where the `key` is the name of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out a nice table with a count of the number of majors for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out the major within each field with the highest unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average unweighted unemployment rate of all the majors in each of the fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this unweighted average representative of what is experienced by the typical graduate in the field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the weighted average unemployment rate in each of the fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
