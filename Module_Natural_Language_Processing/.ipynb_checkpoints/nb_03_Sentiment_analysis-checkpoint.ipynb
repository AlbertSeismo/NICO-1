{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Synopsis\n",
    "\n",
    "So far we have essentially only learned how to parse and enumerate the number of words in text (doesn't sound like much, huh? But that alone comprises a large amount of basic textual analysis). In this unit we will go a bit further and cover:\n",
    "\n",
    "1. Preparing text for further analysis\n",
    "2. Analyzing sentiment\n",
    "\n",
    "We will also talk about how difficult advanced analysis of unstructured text is despite its appearance as an 'easy' task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:32:04.281107Z",
     "start_time": "2022-07-21T15:32:03.055800Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "my_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:32:05.522573Z",
     "start_time": "2022-07-21T15:32:05.182897Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from string import punctuation, whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T20:46:06.647616Z",
     "start_time": "2022-07-21T20:46:06.615819Z"
    }
   },
   "outputs": [],
   "source": [
    "def half_frame(sub, xaxis_label, yaxis_label, font_size = 15, padding = -0.02):\n",
    "    \"\"\"Formats frame, axes, and ticks for matplotlib made graphic \n",
    "       with half frame.\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    # Format graph frame and tick marks\n",
    "    sub.yaxis.set_ticks_position('left')\n",
    "    sub.xaxis.set_ticks_position('bottom')\n",
    "    sub.tick_params(axis = 'both', which = 'major', length = 7, width = 1.5, \n",
    "                    direction = 'out', pad = 10, labelsize = font_size)\n",
    "    sub.tick_params(axis = 'both', which = 'minor', length = 5, width = 1.5, \n",
    "                    direction = 'out', labelsize = 10)\n",
    "    for axis in ['bottom','left']:\n",
    "        sub.spines[axis].set_linewidth(1.5)\n",
    "        sub.spines[axis].set_position((\"axes\", padding))\n",
    "    for axis in ['top','right']:\n",
    "        sub.spines[axis].set_visible(False)\n",
    "\n",
    "    # Format axes\n",
    "    sub.set_xlabel(xaxis_label, fontsize = 1.6 * font_size)\n",
    "    sub.set_ylabel(yaxis_label, fontsize = 1.6 * font_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text emotional valence\n",
    "\n",
    "The notebook about the basics of text analysis illustrated some of the kinds of analyses that one can perform on text corpora.  The focus there was on simple calculations based on patterns of occurrence of work tokens.  Probably, not very satisfying for English or Psychology majors...\n",
    "\n",
    "In this notebook, we are going to skim the surface of a different type of analysis.  Whether the text has positive, neutral, or negative **valence**.  This is typically referred to as sentiment analysis. The idea is that while most words are neutral some words convey valence in a polarized manner.  \n",
    "\n",
    "*Sadness*, *anger*, *despair* convey a very different emotion from *happiness*, *laughter*, or *brightness*.\n",
    "\n",
    "This realization has been formalized by asking many subjects to rate the valence of different words.  The aggregated ratings were then structured into lists where words are given a valence score.\n",
    "\n",
    "Fortunately for us, such work is summarized in data files we can easily access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:48:58.495112Z",
     "start_time": "2022-07-21T15:48:58.460358Z"
    }
   },
   "outputs": [],
   "source": [
    "afinn_folder = Path.cwd() / 'Data' / 'AFINN'\n",
    "\n",
    "print(list((afinn_folder / ).glob('*')))\n",
    "print()\n",
    "\n",
    "valences_file_path = afinn_folder / 'AFINN-111.txt'\n",
    "with open(valences_file_path, 'r', encoding = 'utf-8') as file_in:\n",
    "    valence_data = file_in.readlines() \n",
    "\n",
    "print(len(valence_data))\n",
    "print()\n",
    "\n",
    "print(valence_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That needs a little processing, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:58:33.226508Z",
     "start_time": "2022-07-21T15:58:33.187868Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.split()\n",
    "    print(token, valence)\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    print(valence_dict)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good.\n",
    "\n",
    "Let's remove the `print` and `break` statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:02:24.879954Z",
     "start_time": "2022-07-21T16:02:24.840111Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.split()\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn! Some lines do not have two parts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:02:24.879954Z",
     "start_time": "2022-07-21T16:02:24.840111Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    if len(line.split()) == 2:\n",
    "        token, valence = line.split()\n",
    "    else:\n",
    "        print(line.split())\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Damn!!! Damn!!!**\n",
    "\n",
    "Some of the tokens are not single words.\n",
    "\n",
    "What do you say if we ignore them for now?  We can still read them by noting that a `\\t` character separates the token from the valence, but we will pretend they are not there for the rest of the work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:05:01.898711Z",
     "start_time": "2022-07-21T16:05:01.865211Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict  = {}\n",
    "for line in valence_data:\n",
    "    token, valence = line.strip().split('\\t')\n",
    "    valence_dict[token.strip()] = float(valence.strip())\n",
    "    \n",
    "print(len(valence_dict)) \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words for sure are in this `dictionary`, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:05:28.656889Z",
     "start_time": "2022-07-21T16:05:28.628304Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:05:39.851912Z",
     "start_time": "2022-07-21T16:05:39.824940Z"
    }
   },
   "outputs": [],
   "source": [
    "valence_dict['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A detour for creating our own_library\n",
    "\n",
    "I would like us to work with the play **Othello, the moor of Venice**. We could go back to the *basics* notebook but that is silly. Why would we want to keep a large number of versions of the same code across many notebooks?\n",
    "\n",
    "For one, improvements made in one copy do not transfer to all the other copies.\n",
    "\n",
    "For another, opening the other notebook and copying and pasting the code is annoying and creates issues if we forget to load some needed library.\n",
    "\n",
    "So, how to solve this?\n",
    "\n",
    "**Well, we will create our own library!!!!**\n",
    "\n",
    "Go to the notebook with the folder contents of the current working directory and create a new text file\n",
    "\n",
    "<img src = 'Images/create_library_step1.png'>\n",
    "\n",
    "This will create a new file and open it.\n",
    "\n",
    "You then would change its name.\n",
    "\n",
    "<img src = 'Images/create_library_step2.png'>\n",
    "\n",
    "You will notice that the file type has changed now to `Python`.\n",
    "\n",
    "Inside, you can add the functions you want.  I wrote a bunch of them from our prior work.\n",
    "\n",
    "<img src = 'Images/create_library_step3.png'>\n",
    "\n",
    "Don't forget to save (under `File` on the top left corner).\n",
    "\n",
    "Your new library file is now available in your folder.\n",
    "\n",
    "<img src = 'Images/create_library_step4.png'>\n",
    "\n",
    "\n",
    "**Let's import this new library!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:56:07.784395Z",
     "start_time": "2022-07-21T16:56:07.626296Z"
    }
   },
   "outputs": [],
   "source": [
    "import my_nlp_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:56:21.690935Z",
     "start_time": "2022-07-21T16:56:21.660890Z"
    }
   },
   "outputs": [],
   "source": [
    "help(my_nlp_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So professional looking ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:57:22.319656Z",
     "start_time": "2022-07-21T16:57:22.285485Z"
    }
   },
   "outputs": [],
   "source": [
    "help(my_nlp_library.read_text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes! Othello again!\n",
    "\n",
    "Ok, let's load everything that we need to work with this play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:00:32.512222Z",
     "start_time": "2022-07-21T17:00:32.461388Z"
    }
   },
   "outputs": [],
   "source": [
    "shapespeare_path = Path.cwd() / 'Data' / 'Shakespeare.txt'\n",
    "\n",
    "complete_works = my_nlp_library.read_text_file(shapespeare_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:01:50.549651Z",
     "start_time": "2022-07-21T17:01:50.506501Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_play = my_nlp_library.extract_play('THE TRAGEDY OF OTHELLO, MOOR OF VENICE', \n",
    "                                           complete_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:04:17.658608Z",
     "start_time": "2022-07-21T17:04:17.629852Z"
    }
   },
   "outputs": [],
   "source": [
    "personae = my_nlp_library.get_characters(othello_play)\n",
    "print()\n",
    "\n",
    "print(personae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WE ARE READY TO GO!!!**\n",
    "\n",
    "Let's look at what is going on with Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:07:48.977783Z",
     "start_time": "2022-07-21T17:07:48.945356Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_lines = my_nlp_library.get_character_lines('OTHELLO', othello_play)\n",
    "\n",
    "print(len(othello_lines))\n",
    "print()\n",
    "\n",
    "print(othello_lines[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T20:24:08.397551Z",
     "start_time": "2022-07-21T20:24:08.341265Z"
    }
   },
   "outputs": [],
   "source": [
    "othello_words = my_nlp_library.extract_words_from_lines('Othello', othello_lines)\n",
    "\n",
    "print(len(othello_words))\n",
    "print()\n",
    "\n",
    "print(othello_words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating emotional valences\n",
    "\n",
    "Now that we have Othello's words, we can compare them to the keys of the valence dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T20:38:41.859592Z",
     "start_time": "2022-07-21T20:38:41.826239Z"
    }
   },
   "outputs": [],
   "source": [
    "valence = 0\n",
    "count = 0\n",
    "corpus = othello_words[:]\n",
    "for word in corpus:\n",
    "    if word in valence_dict.keys():\n",
    "#         print(f\"{word:>20} -- {valence_dict[word]}\")\n",
    "        count += 1\n",
    "        valence += valence_dict[word]\n",
    "        \n",
    "print(f\"\\n\\nThe valence of the provided corpus is {valence / count:.3f}\") \n",
    "\n",
    "print(f\"\\nOut of {len(corpus)} words, {count} had a non-zero valence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that fewer than 10% of words have a non-zero valence. \n",
    "\n",
    "There are a other problems, however. *Very happy* should have higher valence than *happy*. And *not happy* should have a negative valence.  \n",
    "\n",
    "Our bag-of-words approach does not account for these possibilities.\n",
    "\n",
    "Let's ignore that issue for now, and attempt to check whether the valence of Othello's speech changes in the course of the play.\n",
    "\n",
    "We will do a little trick for this.\n",
    "\n",
    "We will consider blocks of 200 words and move them by steps of 50 words.  This will smooth things a bit and give us some idea of whether there is a change or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T21:12:08.034336Z",
     "start_time": "2022-07-21T21:12:07.902588Z"
    }
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "valences = []\n",
    "corpus = othello_words\n",
    "step = 50\n",
    "window = 500 \n",
    "\n",
    "for i in range(0, len(corpus)-window, step): \n",
    "    temp_corpus = corpus[i:i+int(window / 2)]\n",
    "    count = 0\n",
    "    valence_t = 0\n",
    "    for word in temp_corpus:\n",
    "        if word in valence_dict.keys():\n",
    "            count += 1\n",
    "            valence_t += valence_dict[word]\n",
    "            \n",
    "    times.append(i + int(window / 2))\n",
    "    valences.append(valence_t / count)\n",
    "        \n",
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Word count', 'Emotional valence', font_size = my_fontsize)\n",
    "# Guide to the eye\n",
    "ax.plot([0, 6500], [0, 0], 'k--', lw = 2)\n",
    "ax.fill_between([0, 6500], -2, color = '0.7')\n",
    "\n",
    "# Print window size for easy examination of choices\n",
    "ax.text(50, -1.8, f\"Window: {window} words\")\n",
    "\n",
    "ax.plot(times, valences, 'bo-', label = 'Othello')\n",
    "\n",
    "ax.set_xlim(0, 6400)\n",
    "ax.set_ylim(-2, 2.5)\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That is how we confirm it is a tragedy!** \n",
    "\n",
    "The question, however, is: Was it a tragedy for everyone?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T21:00:47.643156Z",
     "start_time": "2022-07-21T21:00:47.607127Z"
    }
   },
   "outputs": [],
   "source": [
    "iago_lines = my_nlp_library.get_character_lines('IAGO', othello_play)\n",
    "\n",
    "print(len(iago_lines))\n",
    "print()\n",
    "\n",
    "iago_words = my_nlp_library.extract_words_from_lines('Iago', iago_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T21:12:25.443995Z",
     "start_time": "2022-07-21T21:12:25.314884Z"
    }
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "valences = []\n",
    "corpus = iago_words\n",
    "step = 50\n",
    "window = 500 \n",
    "\n",
    "for i in range(0, len(corpus)-window, step): \n",
    "    temp_corpus = corpus[i:i+int(window / 2)]\n",
    "    count = 0\n",
    "    valence_t = 0\n",
    "    for word in temp_corpus:\n",
    "        if word in valence_dict.keys():\n",
    "            count += 1\n",
    "            valence_t += valence_dict[word]\n",
    "         \n",
    "    if count > 0:\n",
    "        times.append(i + int(window / 2))\n",
    "        valences.append(valence_t / count)\n",
    "        \n",
    "fig = plt.figure( figsize = (6, 4) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "half_frame(ax, 'Word count', 'Emotional valence', font_size = my_fontsize)\n",
    "# Guide to the eye\n",
    "ax.plot([0, 6500], [0, 0], 'k--', lw = 2)\n",
    "ax.fill_between([0, 6500], -2, color = '0.7')\n",
    "\n",
    "ax.text(50, -1.8, f\"Window: {window} words\")\n",
    "\n",
    "ax.plot(times, valences, 'ro-', label = 'Iago')\n",
    "\n",
    "ax.set_xlim(0, 6400)\n",
    "ax.set_ylim(-2, 2.5)\n",
    "ax.legend(loc = 'best', frameon = False, fontsize = my_fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iago was clearly offended by Othello's happiness at the beginning of the play, don't you think? \n",
    "\n",
    "It might be time to actually to recall the [Othello's story](https://en.wikipedia.org/wiki/Othello)...\n",
    "\n",
    "Not bad, ah?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "If I still need to give you exercises, instead of you thinking about something that you would like to do, then I am not doing my job properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "169.567px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
